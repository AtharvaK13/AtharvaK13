## Hello there!ðŸ‘‹

I'm Atharva â€“ a Masters graduate in Computer Science  with a passion for turning complex data puzzles into sleek machine learning solutions! ðŸš€ When I'm not training models or diving deep into algorithms, you'll probably find me experimenting with code, exploring new tech, or chasing the next big AI breakthrough.
I'm constantly learning and re-learning (basics are important!)

Iâ€™m currently working on building an end-to-end ML application with the following workflow:

Data Gathering: Collecting relevant data for the project.
Data Cleaning: Preprocessing and ensuring data quality.
Data Storage: Leveraging FEAST for feature storage.
Model Training: Developing and training a robust ML model.
Application Development: Building a user-facing application for deployment.
Deployment: Using a Docker container to deploy the application on a virtual machine (VM).


Stay tuned for the updates!
<!--
**AtharvaK13/AtharvaK13** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->

##Skills

Programming Languages: Python,, MATLAB, GPU Kernels.
Frameworks: PyTorch, TensorFlow, PyTorch TensorBoard, OpenCV, PIL, NumPy, Matplotlib, TensorRT.
MLOps Frameworks: MLflow, Kubeflow.
Tools: Git, Kubernetes, Docker, ROS, Linux, JIRA.
Cloud Providers: GCP, AWS
Machine Learning Concepts:
- 1 Data Preparation: Data Cleaning, Data Augmentation, Parsing Annotations, and Data Loading (Data Loaders + Transforms(Manual + automatic))
- 2 Model Preparation: 
  - Stage 1: Building Models, Training Models, Loss functions, Optimizers, Hyper-parameter Tuning
  - Stage 2: Making Predictions, Evalution metrics
- 3 Experiment Tracking using Tensorboard - Logging training metrics, visualizing model architecture, and tracking experiments over time.
- 4 Transfer Learning - Leveraging pre-trained/foundation models and fine-tuning them for Computer Vision tasks. Can find best trade-offs between highest accuracy and lowest Parameters for selecting the foundational model.
- 5 Additional Basic Concepts - Dealing with tensors, Autograd, GPU Utilization (model training and inference), Handling Overfitting, Batch Normalization
- 6 Architectures:
  - Classification: ResNet, EfficientNet, VGG, InceptionNet
  - Detection : Faster RCNN (Not for real time detection), ROI Pooling, Region Proposal Network, YOLO, Detectron2 (Not for real time detection), SSD
  - Segmentation: U-Net, Mask RCNN.
  - Generative: GANs, Stable Diffusion
  - Graph Neural Networks: Graph Convolutional Networks, Graph Attention Networks
  - LLMs, BERT, RoBERTa, T5
- 7 Specialized Techniques:
  - NLP techniques: Tokenization, Stemming, Lemmatization, Embedding generation.
  - GenAI - RAG, LLM finetuning using PEFT, LoRA and QLoRA
  - Classical Computer Vision: Image Processing, Denoising, Camera Calibration, Pose Estimation.
  - Modern Computer Vision (Deep Learning): Object Classification, Detection, and Segmentation.
  - Graph Machine Learning: Generating graphs, generating embeddings, Node Classification, Link Prediction, Graph Clustering.




Certifications:
- 1. Deep Learning Specialization by Deeplearning.ai (https://www.coursera.org/account/accomplishments/specialization/T3EZPNB85SWK)
- 2. Introduction to AI/ML toolkits with Kubeflow by edX (https://courses.edx.org/certificates/847de3aab19a484ba477cee47f9bc9b8)
- 3. LLMOps by Google Cloud on DeepLearning.ai (https://learn.deeplearning.ai/accomplishments/0c9fa469-66dd-4c69-b462-079ec85c7846?usp=sharing)
- 4. Machine Learning by Andrew Ng on Coursera (https://www.coursera.org/account/accomplishments/records/2R6S34P9BH98)
 
